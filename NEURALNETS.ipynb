{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import seaborn as sns\n",
    "from copy import deepcopy\n",
    "from collections import OrderedDict\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.max_columns = 1000\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.set_option('precision',2)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = ['marital', 'education', 'job', 'contact', 'poutcome']\n",
    "def make_dummies(df, lst):\n",
    "    temp = deepcopy(df)\n",
    "    Y = df['y']\n",
    "    temp = temp.drop(['y'], axis=1)\n",
    "    for col in temp:\n",
    "        if temp[col].dtype == 'object':\n",
    "            tmp = pd.get_dummies(temp[col], prefix=col)\n",
    "            num_col = len(tmp.columns)\n",
    "            tmp = tmp.iloc[:,0:num_col-1]\n",
    "            temp.drop([col], axis=1,inplace=True)\n",
    "            lst = [temp, tmp]\n",
    "            temp = pd.concat(lst, axis=1)\n",
    "    return temp, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bankFull = pd.read_csv(\"bank-full.csv\", delimiter=\";\")\n",
    "df_bank = pd.read_csv(\"bank.csv\", delimiter=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardizing Numerical Variables\n",
    "\n",
    "- Standardizing the data is essential for clustering algorithms and dimension reduction.\n",
    "- It's not necessary for tree based algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfBankFull = deepcopy(df_bankFull)\n",
    "cols_to_norm = ['age', 'balance', 'duration', 'day','campaign', 'pdays','previous']\n",
    "dfBankFull[cols_to_norm] = dfBankFull[cols_to_norm]\\\n",
    "    .apply(lambda x: (x - x.min()) / (x.max()-x.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainDF, y = make_dummies(dfBankFull, lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downsampling Majority Class:\n",
    "\n",
    "- In the cell directly below you can see the big imbalance between the two classes we're trying to predict. We're going to need to fix this so when it's fed into our models there is no prediction bias toward any one class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     39922\n",
       "yes     5289\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [mainDF, y]\n",
    "df = pd.concat(frames, axis=1)\n",
    "df_maj = df[df.y=='no']\n",
    "df_min = df[df.y=='yes']\n",
    "df_majority_downsampled = resample(df_maj, replace=False,\n",
    "                                  n_samples=5289,\n",
    "                                  random_state=101)\n",
    "\n",
    "frames_resampled = [df_majority_downsampled,df_min]\n",
    "df_resampled = pd.concat(frames_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     5289\n",
       "yes    5289\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resampled['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_resampled.drop(['y'], axis=1),\n",
    "                                                    df_resampled['y'], test_size=.3, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network via Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(30,60,90), activation='relu', solver='adam', random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(30, 60, 90), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=101,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.fit(x_train, y_train)\n",
    "predictions = mlp.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1296  285]\n",
      " [ 228 1365]]\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         no       0.85      0.82      0.83      1581\n",
      "        yes       0.83      0.86      0.84      1593\n",
      "\n",
      "avg / total       0.84      0.84      0.84      3174\n",
      "\n",
      "\n",
      "\n",
      "0.8383742911153119\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))\n",
    "print(\"\\n\")\n",
    "print(classification_report(y_test,predictions))\n",
    "print(\"\\n\")\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
